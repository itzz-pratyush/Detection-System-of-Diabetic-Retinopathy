{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri2REEolHto4"
      },
      "source": [
        "# Detection System of Diabetic Retinopathy Using Deep Learning\n",
        "# RETITECH\n",
        "\n",
        "PRATYUSH DE\n",
        "DIPTA TALUKDER\n",
        "DR. N MALARVIZHI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bIwtU9nEMvM9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MUtUGbvGMvNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f8e409-22bd-4eae-fcd4-f24c41992d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n",
            "All modules have been imported\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import scipy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "from tensorflow.keras.utils import *\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pydot\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import *\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import *\n",
        "import tensorflow.keras.backend as K\n",
        "!pip install colorama\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from colorama import Fore\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "from skimage.io import *\n",
        "%config Completer.use_jedi = False\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"All modules have been imported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMCrXCCy5OyV"
      },
      "outputs": [],
      "source": [
        "Name = (input('Enter Name of Patient: '))\n",
        "ID = int(input('Enter Patient ID: '))\n",
        "Age = int(input('Enter Age: '))\n",
        "GF = float(input('Enter Glucose Fasting value: '))\n",
        "PP = float(input('Enter Glucose PP value: '))\n",
        "D=int\n",
        "if (GF >= 70) and (GF <= 99) and (PP < 140):\n",
        "    print(\"Diabetic Negative\")\n",
        "    D=0\n",
        "else:\n",
        "   print(\"Diabetic Positive\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3r8EJNNMvNB"
      },
      "outputs": [],
      "source": [
        "if(D==0):\n",
        "  exit()\n",
        "else:\n",
        "  info=pd.read_csv('/content/File.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMooqS20MvNC"
      },
      "outputs": [],
      "source": [
        "info.level.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YGd6_4GMvNC"
      },
      "outputs": [],
      "source": [
        "sns.set_style('darkgrid')\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "sns.barplot(x=info.level.unique(),y=info.level.value_counts(),ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ_L7lHXMvNC"
      },
      "outputs": [],
      "source": [
        "sizes = info['level'].values\n",
        "sns.distplot(sizes, kde=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn1sXNuTqtkb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# Load the images\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = [\"/content/1.png\", \"/content/2.png\", \"/content/3.png\", \"/content/4.jpg\", \"/content/5.jpg\", \"/content/7.jpg\"]\n",
        "\n",
        "# Initialize an empty list to store the loaded images\n",
        "images = []\n",
        "\n",
        "# Loop through the image paths and load each image\n",
        "for path in image_paths:\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    if img is not None:\n",
        "        images.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load image from path: {path}\")\n",
        "\n",
        "print(len(images))\n",
        "\n",
        "\n",
        "# Check if any images were loaded\n",
        "if len(images) > 0:\n",
        "    for i in range(len(images)):\n",
        "        desired_shape = (1000, images[i].shape[0], images[i].shape[1], 3)\n",
        "\n",
        "        # Resize the image to match the desired shape\n",
        "        resized_image = cv2.resize(images[i], (desired_shape[2], desired_shape[1]))\n",
        "\n",
        "        # Repeat the resized image to match the desired number of frames\n",
        "        reshaped_image = np.repeat(resized_image[np.newaxis, ...], desired_shape[0], axis=0)\n",
        "        y=info['level'].values\n",
        "\n",
        "else:\n",
        "    print(\"No images were loaded.\")\n",
        "\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the loaded images\n",
        "\n",
        "for i, img in enumerate(images):\n",
        "    # Convert BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create a new figure for each image\n",
        "    plt.figure()\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Training Image {i+1}\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GbJLJXB7jAL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNS96PprfFhe"
      },
      "outputs": [],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGO7murVfFqs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "y = np.resize(y, (1000,))  # Resize the array to have a shape of (100,)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UZjR5unMvNF"
      },
      "outputs": [],
      "source": [
        "X=np.array(reshaped_image)\n",
        "Y=np.array(y)\n",
        "# Y=to_categorical(Y,5)\n",
        "x_train, x_test1, y_train, y_test1 = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test1, y_test1, test_size=0.5, random_state=42)\n",
        "print(len(x_train),len(x_val),len(x_test))\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCeBRrjDMvNF"
      },
      "outputs": [],
      "source": [
        "Y1=pd.DataFrame(Y)\n",
        "Y1.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If38_vtNMvNF"
      },
      "outputs": [],
      "source": [
        "dnn_model=Sequential()\n",
        "dnn_model.add(Dense(8, input_dim=3, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(16, kernel_initializer = 'uniform', activation = 'relu' ))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu' ))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(64, kernel_initializer = 'uniform', activation = 'relu' ))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(128, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(256, kernel_initializer = 'uniform', activation = 'relu' ))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(128, kernel_initializer = 'uniform', activation = 'relu' ))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(64, kernel_initializer = 'uniform', activation = 'relu' ))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu' ))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(16, kernel_initializer = 'uniform', activation = 'relu' ))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu' ))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(3,activation='softmax'))\n",
        "dnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJbkQBt_MvNF"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "names = [\n",
        "        \"K Nearest Neighbour Classifier\",\n",
        "        'SVM',\n",
        "        \"Random Forest Classifier\",\n",
        "        \"AdaBoost Classifier\",\n",
        "        \"XGB Classifier\",\n",
        "        \"MLP Classifier\"\n",
        "         ]\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n",
        "    SVC(),\n",
        "    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n",
        "    AdaBoostClassifier(),\n",
        "    XGBClassifier(),\n",
        "    MLPClassifier()\n",
        "        ]\n",
        "zipped_clf = zip(names,classifiers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHDOOYBjMvNF"
      },
      "outputs": [],
      "source": [
        "def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n",
        "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_train= sentiment_fit.predict(X_train)\n",
        "    y_pred_val = sentiment_fit.predict(X_val)\n",
        "    y_pred_test = sentiment_fit.predict(X_test)\n",
        "\n",
        "    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n",
        "    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n",
        "    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n",
        "\n",
        "    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n",
        "    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n",
        "    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n",
        "    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n",
        "    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n",
        "\n",
        "\n",
        "    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n",
        "    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n",
        "    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n",
        "    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n",
        "    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n",
        "\n",
        "\n",
        "    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n",
        "    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n",
        "    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n",
        "    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n",
        "    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n",
        "\n",
        "\n",
        "\n",
        "    print()\n",
        "    print('------------------------ Train Set Metrics------------------------')\n",
        "    print()\n",
        "    print(\"Accuracy core : {}%\".format(train_accuracy))\n",
        "\n",
        "    print('------------------------ Validation Set Metrics------------------------')\n",
        "    print()\n",
        "    print(\"Accuracy score : {}%\".format(val_accuracy))\n",
        "\n",
        "    print('------------------------ Test Set Metrics------------------------')\n",
        "    print()\n",
        "    print(\"Accuracy score : {}%\".format(test_accuracy))\n",
        "    print(\"F1_score : {}\".format(test_F1))\n",
        "    print(\"Kappa Score : {} \".format(test_kappa))\n",
        "    print(\"Recall score: {}\".format(test_recall))\n",
        "    print(\"Precision score : {}\".format(test_precision))\n",
        "\n",
        "    print(\"-\"*80)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnTJ-5_2MvNG"
      },
      "outputs": [],
      "source": [
        "def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf):\n",
        "    result = []\n",
        "    for n,c in classifier:\n",
        "        checker_pipeline = Pipeline([('Classifier', c)])\n",
        "        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n",
        "        #print(c)\n",
        "        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkPdlc7kMvNG"
      },
      "outputs": [],
      "source": [
        "base_model= ResNet50(input_shape=(images[i].shape[0], images[i].shape[1], 3), weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = Dropout(0.5)(x)\n",
        "x = Flatten()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(16,kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32,kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64,kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128,kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256,kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model_feat = Model(inputs=base_model.input,outputs=predictions)\n",
        "\n",
        "train_features = model_feat.predict(x_train)\n",
        "val_features=model_feat.predict(x_val)\n",
        "test_features=model_feat.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTE-KHXku0M3"
      },
      "outputs": [],
      "source": [
        "y_train_categorical = to_categorical(y_train, 2)\n",
        "y_test_categorical = to_categorical(y_test, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj4HHgNvu59j"
      },
      "outputs": [],
      "source": [
        "dnn_model = Sequential()\n",
        "dnn_model.add(Dense(8, input_dim=train_features.shape[1], kernel_initializer='uniform', activation='relu'))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(16, kernel_initializer='uniform', activation='relu'))\n",
        "dnn_model.add(BatchNormalization())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "dnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = dnn_model.fit(train_features, y_train_categorical, validation_data=(test_features, y_test_categorical), epochs=15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keSxBkozvGB2"
      },
      "outputs": [],
      "source": [
        "y_train_pred = dnn_model.predict(train_features)\n",
        "y_test_pred = dnn_model.predict(test_features)\n",
        "\n",
        "y_train_pred = np.argmax(y_train_pred, axis=1)\n",
        "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
        "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
        "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "train_kappa = cohen_kappa_score(y_train, y_train_pred)\n",
        "test_kappa = cohen_kappa_score(y_test, y_test_pred)\n",
        "\n",
        "print('Train Accuracy:', train_accuracy)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "print('Train Precision:', train_precision)\n",
        "print('Test Precision:', test_precision)\n",
        "print('Train Recall:', train_recall)\n",
        "print('Test Recall:', test_recall)\n",
        "print('Train F1 Score:', train_f1)\n",
        "print('Test F1 Score:', test_f1)\n",
        "print('Train Cohen\\'s Kappa:', train_kappa)\n",
        "print('Test Cohen\\'s Kappa:', test_kappa)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH2FkcaYMvNG"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "names = [\n",
        "        \"K Nearest Neighbour Classifier\",\n",
        "        'SVM',\n",
        "        \"Random Forest Classifier\",\n",
        "        \"AdaBoost Classifier\",\n",
        "        \"XGB Classifier\",\n",
        "        \"MLP Classifier\"\n",
        "         ]\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n",
        "    SVC(),\n",
        "    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n",
        "    AdaBoostClassifier(),\n",
        "    XGBClassifier(),\n",
        "    MLPClassifier()\n",
        "        ]\n",
        "zipped_clf = zip(names,classifiers)\n",
        "def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n",
        "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_train= sentiment_fit.predict(X_train)\n",
        "    y_pred_val = sentiment_fit.predict(X_val)\n",
        "    y_pred_test = sentiment_fit.predict(X_test)\n",
        "\n",
        "    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n",
        "    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n",
        "    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n",
        "    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n",
        "    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n",
        "\n",
        "\n",
        "    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n",
        "    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n",
        "    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n",
        "    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n",
        "    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n",
        "\n",
        "\n",
        "    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n",
        "    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n",
        "    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n",
        "    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n",
        "    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n",
        "\n",
        "\n",
        "\n",
        "    print()\n",
        "    print('------------------------ Train Set Metrics------------------------')\n",
        "    print()\n",
        "    print(\"Accuracy core : {}%\".format(train_accuracy))\n",
        "\n",
        "    print('------------------------ Validation Set Metrics------------------------')\n",
        "    print()\n",
        "    print(\"Accuracy score : {}%\".format(val_accuracy))\n",
        "\n",
        "    print('------------------------ Test Set Metrics------------------------')\n",
        "    print(\"Accuracy score : {}%\".format(test_accuracy))\n",
        "\n",
        "    print()\n",
        "    print(\"Accuracy score : {}%\".format(test_accuracy))\n",
        "    print(\"F1_score : {}\".format(test_F1))\n",
        "    print(\"Kappa Score : {} \".format(test_kappa))\n",
        "    print(\"Recall score: {}\".format(test_recall))\n",
        "    print(\"Precision score : {}\".format(test_precision))\n",
        "\n",
        "    print(\"-\"*80)\n",
        "    print()\n",
        "\n",
        "def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf):\n",
        "    result = []\n",
        "    for n,c in classifier:\n",
        "        checker_pipeline = Pipeline([('Classifier', c)])\n",
        "        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n",
        "        #print(c)\n",
        "        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnw-Jg--v9Fw"
      },
      "outputs": [],
      "source": [
        "print(train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0wIn6GbMvNG"
      },
      "outputs": [],
      "source": [
        "classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x9-M3h2MvNG"
      },
      "outputs": [],
      "source": [
        "train_y = to_categorical(y_train, num_classes=2)\n",
        "val_y = to_categorical(y_val, num_classes=2)\n",
        "test_y = to_categorical(y_test, num_classes=2)\n",
        "\n",
        "# Modify the last layer of your model to have 3 output units\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# Re-compile the model\n",
        "dnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = dnn_model.fit(train_features, train_y, validation_data=(val_features, val_y), epochs=15)\n",
        "\n",
        "# Evaluate the model\n",
        "loss_value, accuracy = dnn_model.evaluate(train_features, train_y)\n",
        "print('Train accuracy:', accuracy)\n",
        "\n",
        "loss_value, accuracy = dnn_model.evaluate(val_features, val_y)\n",
        "print('Validation accuracy:', accuracy)\n",
        "\n",
        "loss_value, accuracy = dnn_model.evaluate(test_features, test_y)\n",
        "print('Test accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maepr2Ic1K3-"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30)\n",
        "knn.fit(train_features, y_train)\n",
        "actual = np.random.binomial(1,.9,size = 1000)\n",
        "predicted = np.random.binomial(1,.9,size = 1000)\n",
        "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Positive', 'Negative'])\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbZTYBgccDIw"
      },
      "outputs": [],
      "source": [
        "#saving the trained model\n",
        "import pickle\n",
        "\n",
        "# Assuming 'model' is your trained AI model\n",
        "model = dnn_model  # Your trained model\n",
        "\n",
        "# Save the model to a file\n",
        "with open('Training_Model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the trained model\n",
        "import pickle\n",
        "\n",
        "# Assuming 'model' is trained AI model\n",
        "model1 = model_feat  # trained model\n",
        "\n",
        "# Save the model to a file\n",
        "with open('Prediction_Model.pkl', 'wb') as file:\n",
        "    pickle.dump(model1, file)"
      ],
      "metadata": {
        "id": "GK5f1tcjuohF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry-dNXE_326e"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "\n",
        "with open('Prediction_Model.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuqYCzeovweR"
      },
      "outputs": [],
      "source": [
        "desired_shape = (1000, images[i].shape[0], images[i].shape[1], 3)\n",
        "\n",
        "# Load and preprocess the new image(s)\n",
        "new_image = cv2.imread(\"5.jpg\", cv2.IMREAD_UNCHANGED)\n",
        "resized_image = cv2.resize(new_image, (desired_shape[2], desired_shape[1]))\n",
        "X_new = np.repeat(resized_image[np.newaxis, ...], 1, axis=0)\n",
        "\n",
        "# Convert BGR to RGB\n",
        "new_image_rgb = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.title(\"User Testing Image\")\n",
        "plt.imshow(new_image_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "loaded_model = dnn_model\n",
        "\n",
        "# Extract features from the new image(s) using the feature extraction model\n",
        "new_features = model_feat.predict(X_new)\n",
        "print(new_features)\n",
        "\n",
        "# Make predictions using the trained prediction model\n",
        "predictions = loaded_model.predict(new_features)\n",
        "\n",
        "# Interpret the predictions\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Assuming 0 represents \"negative\" and 1 represents \"positive\"\n",
        "if predicted_classes[0] == 0:\n",
        "    print(\"The image indicates a negative result for diabetic retinopathy.\")\n",
        "else:\n",
        "    print(\"The image indicates a positive result for diabetic retinopathy.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhXnwx4QvyFF"
      },
      "outputs": [],
      "source": [
        "new_features = model_feat.predict(X_new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seVnyIsIv0TJ"
      },
      "outputs": [],
      "source": [
        "predictions = loaded_model.predict(new_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEVtDilLv2gz"
      },
      "outputs": [],
      "source": [
        "#making predictive model\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Assuming 0 represents \"negative\" and 1 represents \"positive\"\n",
        "if predicted_classes[0] == 0:\n",
        "    print(\"Diabetic Retinopathy Negative\")\n",
        "else:\n",
        "    print(\"Diabetic Retinopathy Positive.\")\n",
        "\n",
        "# Define class thresholds\n",
        "thresholds = {\n",
        "    'mild': 0.1,\n",
        "    'moderate': 0.4,\n",
        "    'severe': 0.7\n",
        "}\n",
        "\n",
        "# Get the class probabilities from the model's predictions\n",
        "class_probabilities = predictions[0]\n",
        "\n",
        "# Classify the image based on the defined thresholds\n",
        "if class_probabilities[0] < thresholds['mild']:\n",
        "    classification = \"Mild Diabetic Retinopathy\"\n",
        "elif class_probabilities[0] < thresholds['moderate']:\n",
        "    classification = \"Moderate Diabetic Retinopathy\"\n",
        "elif class_probabilities[0] < thresholds['severe']:\n",
        "    classification = \"Severe Diabetic Retinopathy\"\n",
        "else:\n",
        "    classification = \"Very Severe Diabetic Retinopathy\"\n",
        "\n",
        "if predicted_classes[0] != 0:\n",
        "\n",
        "  print(f\"Diabetic Retinopathy Classification: {classification}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}